{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5 - Permanent Residency, will I get accepted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries & Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T20:09:35.045882Z",
     "start_time": "2019-03-24T20:09:34.877342Z"
    }
   },
   "outputs": [],
   "source": [
    "# General \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import pickle\n",
    "import operator\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "\n",
    "# Made modules\n",
    "import sys\n",
    "sys.path.append('/Users/laurengilson/Desktop/project5')\n",
    "from cleaning import *\n",
    "from analysisfunctions import *\n",
    "\n",
    "# Modeling functions\n",
    "from sklearn.metrics import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # Prevents kernel from dying when running XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Jupyter Formatting\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## PERM data from Dept. of Labour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T16:57:22.108868Z",
     "start_time": "2019-03-24T16:57:22.105140Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Data available from 2008-2019 \n",
    "years = list(range(2008, 2020))\n",
    "perm_df = GetPermData(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T17:05:05.804279Z",
     "start_time": "2019-03-24T17:05:05.793947Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save original imported df\n",
    "perm_df.to_pickle(\"./perm_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Clean PERM data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T17:09:19.355581Z",
     "start_time": "2019-03-24T17:09:19.351570Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initiate a new dataframe to add cleaned columns to - this will be final dataframe to merge with economic data\n",
    "perm_cleaned_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Clean Y predictor column - Case Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T17:09:00.406421Z",
     "start_time": "2019-03-24T17:08:58.576172Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df['case_status'] = list(map(lambda value : value.lower(), perm_df['case_status']))\n",
    "\n",
    "# Check various outcomes - make sure they are consistent\n",
    "values, counts = np.unique(perm_df['case_status'], return_counts=True)\n",
    "dict(zip(values, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove rows where application was withdrawn, as outcome is unknown\n",
    "perm_df = perm_df.drop(perm_df[perm_df['case_status'] == 'withdrawn'].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Categorise 1 into denied and everything else as 0 into a new column - assume that certified-expired is certified\n",
    "perm_df[\"case_outcome\"] = perm_df[\"case_status\"].apply(Predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Append columns needed for model to cleaned df\n",
    "perm_cleaned_df['case_outcome'] = perm_df['case_outcome'].astype('category')\n",
    "perm_cleaned_df['fiscal_year_of_application'] = perm_df['fiscal_year'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add Processing Center - extracted from case_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# merge case_number and case_no columns - same information currently different headers\n",
    "perm_df['case_number'].fillna(perm_df['case_no'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Letter at beginning of case number represents processing centre - A = Atlanta, C = Chicago\n",
    "perm_df['processing_center'] = [i[0] for i in perm_df['case_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['processing_center'] = perm_df['processing_center'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Clean class of admission - visa which was used to enter the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df['class_of_admission'] = perm_df['class_of_admission'].fillna(str('unknown')) # create unknown category for nulls\n",
    "perm_df['class_of_admission'] = list(map(str, perm_df['class_of_admission']))\n",
    "perm_df['class_of_admission'] = list(map(lambda x:x.lower(), perm_df['class_of_admission']))\n",
    "perm_df['class_of_admission'] = [x.replace('-', '') for x in perm_df['class_of_admission']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['class_of_admission'] = perm_df['class_of_admission'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Clean country of citizenship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Merge two columns as one has a mispelling and should be the same column\n",
    "perm_df['country_of_citizenship'].fillna(perm_df['country_of_citzenship'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use unknown category for nulls and remove punctuation for consistency across countries\n",
    "perm_df['country_of_citizenship'] = perm_df['country_of_citizenship'].fillna(str('unknown'))\n",
    "perm_df['country_of_citizenship'] = list(map(lambda x:x.lower(), perm_df['country_of_citizenship']))\n",
    "perm_df['country_of_citizenship'] = perm_df['country_of_citizenship'].str.replace('(', '')\n",
    "perm_df['country_of_citizenship'] = perm_df['country_of_citizenship'].str.replace(')', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Match country with a 3 letter identifier - makes merging with economic data easier as there are usually \n",
    "# a lot of inconsistencies with names/spellings/abbreviations - therefore, standardizing the countries to 3 letters.\n",
    "perm_df['citizenship_code'] = perm_df['country_of_citizenship'].apply(CountryCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['country_of_citizenship'] = perm_df['citizenship_code'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add column based on whether citizenship and place of birth are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df['fw_info_birth_country'] = StringColumns(perm_df['preparer_info_emp_completed'], new_null='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create column based on citizenship and place of birth are the same - assume they are for unknowns\n",
    "citizenship_same_as_birth = list(ColValueCheck(perm_df['country_of_citizenship'], perm_df['fw_info_birth_country']))\n",
    "perm_df['citizenship_same_as_birth'] = citizenship_same_as_birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['citizenship_same_as_birth'] = perm_df['citizenship_same_as_birth'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Standardize all wage requests into salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df['salary_for_job_requested'] = WageFunction(perm_df['pw_amount_9089'], perm_df['pw_unit_of_pay_9089'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['wage_for_job'] = perm_df['salary_for_job_requested'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Make groupings of 'Standard Occupation Classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df['pw_soc_code'] = list(map(str, perm_df['pw_soc_code']))\n",
    "perm_df['pw_soc_code'] = [i[0:2] for i in perm_df['pw_soc_code']] # First 2 numbers represent main category of work\n",
    "perm_df['pw_soc_code'] = [x.replace('na', '00') for x in perm_df['pw_soc_code']] # Make category of '00' for unknowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['job_soc_code'] = perm_df['pw_soc_code'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add Economic sector for job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df['us_economic_sector'] = StringColumns(perm_df['us_economic_sector'], new_null='unclassified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['job_economic_sector'] = perm_df['us_economic_sector'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add column determining whether the employer prepared the application or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T17:50:11.544646Z",
     "start_time": "2019-03-24T17:50:09.863580Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df['preparer_info_emp_completed'] = StringColumns(perm_df['preparer_info_emp_completed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Change to categories 0 for employer did not (n), 1 for employer did (y)\n",
    "perm_df[\"preparer_info_emp_completed\"] = perm_df[\"preparer_info_emp_completed\"].apply(CategoriseYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['employer_completed_application'] = perm_df['preparer_info_emp_completed'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add Decision Date - useful for looking at applications over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df['decision_date'] = pd.to_datetime(perm_df['decision_date'])\n",
    "# Reduce decision date to month and year as a code - E.g 200811 = November 2008\n",
    "perm_df['decision_date'] = perm_df['decision_date'].map(lambda x: 100*x.year + x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['decision_month_year'] = perm_df['decision_date'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add applicant education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df['foreign_worker_info_education'] = StringColumns(perm_df['foreign_worker_info_education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['applicant_highest_education'] = perm_df['foreign_worker_info_education'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add whether applicant needs training for the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df['job_info_training'] = StringColumns(perm_df['job_info_training'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Change to 0 (not needed) and 1 (needed)\n",
    "perm_df['job_info_training'] = perm_df['job_info_training'].apply(CategoriseYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['training_required'] = perm_df['job_info_training'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Has applicant had layoff in the past six months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df['ri_layoff_in_past_six_months'] = StringColumns(perm_df['ri_layoff_in_past_six_months'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Change to 0 (no) and 1 (yes)\n",
    "perm_df['ri_layoff_in_past_six_months'] = perm_df['ri_layoff_in_past_six_months'].apply(CategoriseYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['layoff_in_past_six_months'] = perm_df['ri_layoff_in_past_six_months'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Has applicant got ownership interest in the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df['fw_ownership_interest'] = StringColumns(perm_df['fw_ownership_interest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# As before 0 (no) and 1 (yes)\n",
    "perm_df['fw_ownership_interest'] = perm_df['fw_ownership_interest'].apply(CategoriseYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['ownership_interest'] = perm_df['fw_ownership_interest'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add number of employees at company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Assume nulls as the mean value\n",
    "perm_df['employer_num_employees'] = perm_df['employer_num_employees'].fillna(perm_df['employer_num_employees'].mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['employer_num_employees'] = perm_df['employer_num_employees'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add applicant's state - as an abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# change all states in two letter abbreviation\n",
    "perm_df['fw_worker_state_abv'] = StateAbbreviation(perm_df['foreign_worker_info_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df['fw_worker_state_abv'] = [x.replace('NONE', 'unknown') for x in perm_df['fw_worker_state_abv']] # Assume nans as n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['worker_state_abv'] = perm_df['fw_worker_state_abv'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add column of whether job is in the same state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Change job state to abbreviations - easier to merge with applicant's state\n",
    "perm_df['job_state_abv'] = StateAbbreviation(perm_df['job_info_work_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# is job in same state - for null values assume the job is in the same state as the applicant\n",
    "job_in_same_state = list(ColValueCheck(perm_df['fw_worker_state_abv'], perm_df['job_state_abv']))\n",
    "perm_df['job_same_state'] = job_in_same_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['job_same_state'] = perm_df['job_same_state'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add whether applicant has required experience for job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# merge cols that should be the same according to schema\n",
    "perm_df['fw_info_rel_occup_exp'].fillna(perm_df['fw_info_rel_occup_experience'], inplace = True)\n",
    "perm_df['fw_info_req_experience'].fillna(perm_df['fw_info_rel_occup_exp'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df['fw_info_req_experience'] = StringColumns(perm_df['fw_info_req_experience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_cleaned_df['has_required_experience'] = perm_df['fw_info_req_experience'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save cleaned dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Drop rows where citizenship is unknown - won't be able to merge economic data\n",
    "perm_cleaned_df = perm_cleaned_df.drop(perm_cleaned_df[perm_cleaned_df['country_of_citizenship'] == 'NA'].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pickle clean df\n",
    "perm_cleaned_df.to_pickle(\"./perm_clean_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import and clean Economic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "economic_list = ['GDP_data','employment_to_pop_ratio','gov_expenditure_education','percentage_of_immigrants','net_migration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cleaned_econ_dfs = []\n",
    "\n",
    "for data in economic_list:\n",
    "    cleaned_econ_dfs.append(CleanEconomic(data)) # add to a list - to append to PERM dataframe individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Merge PERM and Economic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Merge each of the economic dataframes to main PERM dataframe dependent on year of application and citizenship\n",
    "for cleaned_df in cleaned_econ_dfs:\n",
    "    perm_df_cleaned  = pd.merge(perm_df_cleaned, cleaned_df,  how='left', left_on=['country_of_citizenship','fiscal_year_of_application'], right_on = ['Country Code','year'])\n",
    "    perm_df_cleaned.drop(['Country Code','year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add column of which political party was in office at time of application decision - useful for analysis over time\n",
    "perm_df_cleaned['political_party'] = (perm_df_cleaned['decision_month_year'].apply(PoliticalParty).astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pickle final dataframe for analysis\n",
    "perm_df_cleaned.to_pickle(\"./final_clean_df.pkl\")\n",
    "perm_df_cleaned.to_csv('full_perm_data.csv', index=False) # Save to csv - easier if working with Tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Assess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:15:06.639038Z",
     "start_time": "2019-03-24T19:15:05.973164Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df_cleaned = pd.read_pickle(\"./final_clean_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:15:29.390721Z",
     "start_time": "2019-03-24T19:15:28.461631Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Double check nulls have been dropped - cleaning process has altered these values dependent on column\n",
    "perm_df_cleaned.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:15:48.399070Z",
     "start_time": "2019-03-24T19:15:48.319889Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check data imbalance\n",
    "print(f\" Certified: {((perm_df_cleaned.case_outcome.value_counts()[0]/perm_df_cleaned.case_outcome.count())*100).round(2)}%\")\n",
    "print(f\" Denied: {((perm_df_cleaned.case_outcome.value_counts()[1]/perm_df_cleaned.case_outcome.count())*100).round(2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:16:07.385129Z",
     "start_time": "2019-03-24T19:16:07.277186Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:16:27.993667Z",
     "start_time": "2019-03-24T19:16:27.331502Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_df_cleaned.info() # Check columns are in correct format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:16:47.931861Z",
     "start_time": "2019-03-24T19:16:47.927159Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initialising a random state - to be consistent throughout\n",
    "rs=27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dummy categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:17:07.352905Z",
     "start_time": "2019-03-24T19:17:07.337576Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a list of just categorical columns in dataframe - used to get dummies\n",
    "categories = []\n",
    "for col in list(perm_df_cleaned.columns)[1:]:\n",
    "    if perm_df_cleaned[col].dtype == 'float64' or perm_df_cleaned[col].dtype == 'int64':\n",
    "        None\n",
    "    else:\n",
    "        categories.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:17:32.110330Z",
     "start_time": "2019-03-24T19:17:26.419493Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm_dummied = perm_df_cleaned.join(pd.get_dummies(perm_df_cleaned[categories], drop_first=True))\n",
    "perm_dummied.drop(categories, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Undersample & split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Oversampling to 1.5million is too computationally expensive with over 500 columns - so using undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:17:53.554722Z",
     "start_time": "2019-03-24T19:17:53.002276Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = perm_dummied.drop('case_outcome', axis=1)\n",
    "y = perm_dummied['case_outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:18:47.404755Z",
     "start_time": "2019-03-24T19:18:15.608742Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split data using all of the features in the dataset - this function ensures redefining the data if less columns are \n",
    "# used more straightforward - can access the data via the dictionary and key values\n",
    "all_features = SplitData(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Random Forest - All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:21:40.630121Z",
     "start_time": "2019-03-24T19:21:32.057042Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_all = RandomForestClassifier(random_state=rs).fit(all_features['X_train'], all_features['y_train'])\n",
    "rf_all_pred = rf_all.predict(all_features['X_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:22:58.023079Z",
     "start_time": "2019-03-24T19:22:02.979057Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ErrorMetrics(rf_all, \"Random Forest, All Features\", all_features['X_train'], all_features['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:23:22.176589Z",
     "start_time": "2019-03-24T19:23:22.024065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_all_cm = confusion_matrix(all_features['y_val'], rf_all_pred)\n",
    "PrintConfusionMatrix(rf_all_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:23:22.186741Z",
     "start_time": "2019-03-24T19:21:13.260Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ROC_AUC(rf_all, \"Random Forest All features\", all_features['y_val'], all_features['X_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree - All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = DecisionTreeClassifier(random_state=rs).fit(all_features['X_train'], all_features['y_train'])\n",
    "y_pred_dec_tree = dec_tree.predict(all_features['X_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorMetrics(dec_tree, 'Decision Tree, All features', all_features['X_train'], all_features['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_cm = confusion_matrix(all_features['y_val'], y_pred_dec_tree)\n",
    "PrintConfusionMatrix(dec_tree_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_AUC(dec_tree, 'Decision Tree, All features', all_features['y_val'], all_features['X_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance, in order and with correct column names\n",
    "features = list(dec_tree.feature_importances_.round(3))\n",
    "column_names = list(perm_dummied.columns.drop('case_outcome'))\n",
    "importance = dict(zip(column_names, features))\n",
    "dec_tree_ordered_importance = sorted(importance.items(), key=operator.itemgetter(1), reverse=True)\n",
    "dec_tree_ordered_importance[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine top feature importance and separate list\n",
    "most_important = [k for k,v in importance.items() if v>=0.004]\n",
    "most_important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Grid Search to find optimal parameters for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=rs)\n",
    "# Currently default parameters used in random forest classifier\n",
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set various parameters to test\n",
    "params_to_test = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [2, 5, 10],\n",
    "    'max_features':[2,3],\n",
    "    'min_samples_leaf':[3,4,5],\n",
    "    'min_samples_split':[8,10,12],\n",
    "    'n_estimators':[100,200,500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=rf, param_grid=params_to_test, cv=3, n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Takes approx 45 minutes\n",
    "grid_search.fit(all_features['X_train'], all_features['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_rf_params = grid_search.best_params_\n",
    "best_rf_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```{'bootstrap': True,\n",
    "    'max_depth' : 10,\n",
    "    'max_features' : 3, \n",
    "    'min_samples_leaf' : 3,\n",
    "    'min_samples_split' : 10, \n",
    "    'n_estimators' : 500}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_rf_estimator = grid_search.best_estimator_\n",
    "best_rf_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                        max_depth=10, max_features=3, max_leaf_nodes=None,\n",
    "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                        min_samples_leaf=3, min_samples_split=10,\n",
    "                        min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
    "                        oob_score=False, random_state=27, verbose=0, warm_start=False)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Random Forest - All features & Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_all_best_params = best_rf_estimator.fit(all_features['X_train'], all_features['y_train'])\n",
    "rf_all_best_pred = rf_all_best_params.predict(all_features['X_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ErrorMetrics(rf_all_best_params, 'Random Forest, All features, Best Parameters', all_features['X_train'], all_features['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_all_best_params_cm = confusion_matrix(all_features['y_val'], rf_all_best_pred)\n",
    "PrintConfusionMatrix(rf_all_best_params_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ROC_AUC(rf_all_best_params, \"Random Forest, All features, Best Parameters\", all_features['y_val'], all_features['X_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Random Forest - Top features & Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Resplit data with most important features\n",
    "most_imp_X = perm_dummied[most_important]\n",
    "most_imp_y = perm_dummied['case_outcome']\n",
    "\n",
    "most_important_features = SplitData(most_imp_X, most_imp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_top_feats = best_rf_estimator.fit(most_important_features['X_train'], most_important_features['y_train'])\n",
    "y_pred_top_feats = rf_top_feats.predict(most_important_features['X_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ErrorMetrics(rf_top_feats, 'Random Forest, Top Features', most_important_features['X_train'], most_important_features['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_top_feats_cm = confusion_matrix(most_important_features['y_val'], y_pred_top_feats)\n",
    "PrintConfusionMatrix(rf_top_feats_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ROC_AUC(rf_top_feats, \"Random Forest, Top Features\", most_important_features['y_val'], most_important_features['X_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Naive Bayes - All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "naive_bayes = GaussianNB().fit(all_features['X_train'], all_features['y_train'])\n",
    "y_naive_pred = naive_bayes.predict(all_features['X_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ErrorMetrics(naive_bayes, 'Naive Bayes All Features', all_features['X_train'], all_features['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nb_cm = confusion_matrix(all_features['y_val'], y_naive_pred)\n",
    "PrintConfusionMatrix(nb_cm, ['Certified', 'Denied'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ROC_AUC(naive_bayes, \"Naive Bayes All features\", all_features['y_val'], all_features['X_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:37:35.739815Z",
     "start_time": "2019-03-24T19:37:35.733410Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Naive Bayes - Top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "naive_bayes_most_imp = GaussianNB().fit(most_important_features['X_train'], most_important_features['y_train'])\n",
    "y_naive_pred_most_imp = naive_bayes_most_imp.predict(most_important_features['X_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ErrorMetrics(naive_bayes_most_imp, 'Naive Bayes Most Imp Features', most_important_features['X_train'], most_important_features['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nb_most_imp_cm = confusion_matrix(most_important_features['y_val'], y_naive_pred_most_imp)\n",
    "PrintConfusionMatrix(nb_most_imp_cm, ['Certified', 'Denied'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ROC_AUC(naive_bayes_most_imp, \"Naive Bayes Most imp features\", most_important_features['y_val'], most_important_features['X_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Grid Search for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define parameters to search for XGBoost\n",
    "gridsearch_params = {\n",
    "        'max_depth': [3, 4],\n",
    "        'learning_rate':[0.02, 0.05],\n",
    "        'min_child_weight': [1, 5],\n",
    "        'gamma': [0.5, 1, 2],\n",
    "        'subsample': [0.6, 0.8],\n",
    "        'colsample_bytree': [0.6, 0.8],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb_grid = xgb.XGBClassifier(n_estimator=50000, objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid_search_xgb = GridSearchCV(estimator = xgb_grid, param_grid = gridsearch_params, cv=3, n_jobs = -1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Runtime: approx 4hours\n",
    "grid_search_xgb.fit(all_features['X_train'], all_features['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid_search_xgb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```{'colsample_bytree': 0.8,\n",
    " 'gamma': 1,\n",
    " 'learning_rate': 0.05,\n",
    " 'max_depth': 4,\n",
    " 'min_child_weight': 1,\n",
    " 'subsample': 0.8}\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost - All features & Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgb = xgb.XGBClassifier(n_estimators=30000,\n",
    "                                   max_depth=4,\n",
    "                                   objective='binary:logistic',\n",
    "                                   gamma=1,\n",
    "                                   learning_rate=0.05,\n",
    "                                   subsample=0.8,\n",
    "                                   min_child_weight=1,\n",
    "                                   colsample_bytree=0.8\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set_all = [(all_features['X_train'],all_features['y_train']), (all_features['X_val'], all_features['y_val'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgb.fit(all_features['X_train'],all_features['y_train'], \n",
    "                    eval_set=eval_set_all,\n",
    "                    eval_metric='error', # error = 1 - accuracy \n",
    "                    early_stopping_rounds=20, # stop after 20 rounds if no improvement in error\n",
    "                    verbose=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_pred = best_params_xgb.predict(all_features['X_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cm = confusion_matrix(all_features['y_val'], best_params_pred)\n",
    "PrintConfusionMatrix(xgb_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ErrorMetrics runs too slowly for XGBoost - manual print instead\n",
    "print(f\"Accuracy: {accuracy_score(best_params_xgb.predict(all_features['X_val'], all_features['y_val'])}\")\n",
    "print(f\"Precision: {precision_score(best_params_xgb.predict(all_features['X_val'], all_features['y_val'])}\")\n",
    "print(f\"Recall: {recall_score(best_params_xgb.predict(all_features['X_val'], all_features['y_val'])}\")\n",
    "print(f\"F1: {f1_score(best_params_xgb.predict(all_features['X_val'], all_features['y_val'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with decision tree importances to determine which are most/least for interpretation\n",
    "xgb.plot_importance(best_params_xgb, max_num_features=10)\n",
    "xgb.plot_importance(best_params_xgb, max_num_features=10, importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_features = list(best_params_xgb.feature_importances_.round(3))\n",
    "xgb_importance = dict(zip(column_names, xgb_features))\n",
    "xgb_ordered_importance = sorted(importance.items(), key=operator.itemgetter(1), reverse=True)\n",
    "xgb_ordered_importance[:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## XGBoost  - Top features & Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_params_top_feats = xgb.XGBClassifier(n_estimators=30000,\n",
    "                                   max_depth=4,\n",
    "                                   objective='binary:logistic',\n",
    "                                   gamma=1,\n",
    "                                   learning_rate=0.05,\n",
    "                                   subsample=0.8,\n",
    "                                   min_child_weight=1,\n",
    "                                   colsample_bytree=0.8\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_eval_most_imp = [(most_important_features['X_train'],most_important_features['y_train']), (most_important_features['X_val'], most_important_features['y_val'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_params_top_feats.fit(most_important_features['X_train'],most_important_features['y_train'], \n",
    "                          eval_set=new_eval_most_imp,\n",
    "                          eval_metric='error', # error = 1 - accuracy \n",
    "                          early_stopping_rounds=20, # stop after 20 rounds if no improvement in error\n",
    "                          verbose=True\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb_top_feats_pred = best_params_top_feats.predict(most_important_features['X_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb_cm = confusion_matrix(most_important_features['y_val'], xgb_top_feats_pred)\n",
    "PrintConfusionMatrix(xgb_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy_score(best_params_top_feats.predict(most_important_features['X_val'], most_important_features['y_val'])}\")\n",
    "print(f\"Precision: {precision_score(best_params_top_feats.predict(most_important_features['X_val'], most_important_features['y_val'])}\")\n",
    "print(f\"Recall: {recall_score(best_params_top_feats.predict(most_important_features['X_val'], most_important_features['y_val'])}\")\n",
    "print(f\"F1: {f1_score(best_params_top_feats.predict(most_important_features['X_val'], most_important_features['y_val'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ROC_AUC(best_params_top_feats, \"XGBoost Top features\", most_important_features['y_val'], most_important_features['X_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Try Voting Classifier - Random Forest & Naive Bayes - All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_vote = perm_dummied.drop('case_outcome', axis=1)\n",
    "y_vote = perm_dummied['case_outcome']\n",
    "voting = SplitData(X_vote, y_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define classifiers to vote against\n",
    "clf1 = best_rf_estimator\n",
    "clf2 = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hard_vote = VotingClassifier(estimators=[('RF', clf1), ('naive_bayes', clf2)], voting='hard').fit(voting['X_train'], voting['y_train'])\n",
    "hard_pred = hard_vote.predict(voting['X_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hard_vote_cm = confusion_matrix(voting['y_val'], hard_pred)\n",
    "PrintConfusionMatrix(hard_vote_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "soft_vote = VotingClassifier(estimators=[('RF', clf1), ('naive_bayes', clf2)], voting='soft').fit(voting['X_train'], voting['y_train'])\n",
    "soft_pred = soft_vote.predict(voting['X_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "soft_vote_cm = confusion_matrix(voting['y_val'], soft_pred)\n",
    "print_confusion_matrix(soft_vote_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ROC_AUC(soft_vote, \"Soft Vote\", voting['y_val'], voting['X_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Weighted Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Try combinations of weightings using itertools product to find optimal pairing\n",
    "pairing = []\n",
    "accuracy = []\n",
    "\n",
    "for item in list(product('123456789', repeat=2)):\n",
    "    weights = [int(item[0]), int(item[1])]\n",
    "    \n",
    "    weight_vote = VotingClassifier(estimators=[('RF', clf1), ('naive_bayes', clf2)], voting='soft', weights=weights, flatten_transform=True).fit(voting['X_train'], voting['y_train'])\n",
    "    weight_pred = weight_vote.predict(voting['X_val'])\n",
    "    \n",
    "    pairing.append(weights)\n",
    "    accuracy.append(weight_vote.score(voting['X_train'], voting['y_train']))\n",
    "    \n",
    "\n",
    "optimal_pair = pairing[accuracy.index(max(accuracy))]\n",
    "\n",
    "print(f\"Pairing: {optimal_pair}, Accuracy: {accuracy.index(max(accuracy))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weight_vote = VotingClassifier(estimators=[('RF', clf1), ('naive_bayes', clf2)], voting='soft', weights=optimal_pair, flatten_transform=True).fit(voting['X_train'], voting['y_train'])\n",
    "weight_pred = weight_vote.predict(voting['X_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weight_vote_cm = confusion_matrix(voting['y_val'], weight_pred)\n",
    "PrintConfusionMatrix(weight_vote_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ROC_AUC(weight_vote, \"VotingWeighted\", voting['y_val'], voting['X_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on hold out data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions:** \n",
    "- Best performing model - XGBoost with top features and optimal parameters\n",
    "- **Accuracy:** 73.3%\n",
    "- **Precision:** 70.0%\n",
    "- **AUC:** 0.816\n",
    "- **FPR:** 14.7% (Total) 29.4% (Denied Cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = best_params_top_feats.predict(most_important_features['X_hold_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = confusion_matrix(most_important_features_features['y_hold_out'], final_preds)\n",
    "PrintConfusionMatrix(final_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T19:57:56.710537Z",
     "start_time": "2019-03-24T19:57:47.875Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy_score(best_params_top_feats.predict(most_important_features['X_hold_out'], most_important_features['y_hold_out']))}\")\n",
    "print(f\"Precision: {precision_score(best_params_top_feats.predict(most_important_features['X_hold_out'], most_important_features['y_hold_out']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at which features appear in the top 10 features for Dec Trees & XGBoost\n",
    "dec_tree_top_ten = dec_tree_ordered_importance[:11]\n",
    "dec_tree_lowest_ten = dec_tree_ordered_importance[-10:]\n",
    "xgb_top_ten = xgb_ordered_importance[:11]\n",
    "xgb_lowest_ten = xgb_ordered_importance[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common most influential features\n",
    "matching_highest = []\n",
    "\n",
    "for dt in dec_tree_top_ten:\n",
    "    for xgb in xgb_top_ten:\n",
    "        if dt[0] == xgb[0]:\n",
    "            matching_highest.append(dt[0])\n",
    "\n",
    "matching_highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common least influential features\n",
    "matching_lowest = []\n",
    "\n",
    "for dt in dec_tree_lowest_ten:\n",
    "    for xgb in xgb_lowest_ten:\n",
    "        if dt[0] == xgb[0]:\n",
    "            matching_lowest.append(dt[0])\n",
    "\n",
    "matching_lowest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at applications & outcomes over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T14:55:24.686372Z",
     "start_time": "2019-03-25T14:55:24.515232Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rejections = pd.DataFrame(perm_df.groupby('fiscal_year_of_application')['case_outcome'].value_counts())\n",
    "rejections.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of rejections per year\n",
    "percentage_of_rejecs = []\n",
    "for i in range(0, 24, 2):\n",
    "    percentage_of_rejecs.append(round((rejections.iloc[i+1][0]/(rejections.iloc[i][0]+rejections.iloc[i+1][0])*100),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = list(range(2008, 2020))\n",
    "year_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rejection rate over time (year)\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(year_list, percentage_of_rejecs)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Percentage of Application Rejections');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot raw number of applications over time\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(year_list[:-1], list(application['case_outcome'][:-1]))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Applications');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rejection Number & Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_month = pd.DataFrame(perm_df.groupby('decision_month_year')['case_outcome'].value_counts())\n",
    "each_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of decisions in each month being rejections\n",
    "month_percentage = []\n",
    "for i in range(0, (perm_df['decision_month_year'].nunique()*2), 2):\n",
    "    month_percentage.append(round((each_month.iloc[i+1][0]/(each_month.iloc[i][0]+each_month.iloc[i+1][0])*100),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Number of rejections per month \n",
    "month_number = []\n",
    "for i in range(0, (perm_df['decision_month_year'].nunique()*2), 2):\n",
    "    month_number.append(round((each_month.iloc[i+1][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make months unto more readable terms for graphs\n",
    "months = []\n",
    "\n",
    "for month in sorted(list(perm_df['decision_month_year'].unique())):\n",
    "    date = datetime.datetime.strptime(str(month), '%Y%m')\n",
    "    months.append(date.strftime(\"%b %Y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include political party information \n",
    "democratic_start = months[months.index('Jan 2009')] \n",
    "democratic_end = months[months.index('Jan 2017')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot percentage of rejections \n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(months, month_percentage)\n",
    "plt.xticks(months[::12], rotation=45)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Percentage of Application Rejections')\n",
    "\n",
    "# Shade political party in office at time - democratic - blue, republican - red\n",
    "plt.axvspan(months[0], democratic_start, alpha=0.2, color='r')\n",
    "plt.axvspan(democratic_start, democratic_end, alpha=0.2, color='b')\n",
    "plt.axvspan(democratic_end, months[-1], alpha=0.2, color='r')\n",
    "\n",
    "for month in months[::12]:\n",
    "    plt.axvline(month, color='0.5', zorder=0, linestyle=':');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw number of rejections \n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(months, month_number)\n",
    "plt.xticks(months[::12], rotation=45)\n",
    "plt.xlabel('Fiscal Year')\n",
    "plt.ylabel('Number of Application Rejections')\n",
    "\n",
    "# Shade political party in office at time\n",
    "plt.axvspan(months[0], democratic_start, alpha=0.2, color='r')\n",
    "plt.axvspan(democratic_start, democratic_end, alpha=0.2, color='b')\n",
    "plt.axvspan(democratic_end, months[-1], alpha=0.2, color='r')\n",
    "\n",
    "for month in months[::12]:\n",
    "    plt.axvline(month, color='0.5', zorder=0, linestyle=':');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of applications per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_month = perm_df.groupby(['decision_month_year']).agg('count')\n",
    "application_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot total number of applications per month - can compare with percentage of rejections see if there's correlation \n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(months, list(application_month['case_outcome']))\n",
    "plt.xticks(new_year, rotation=45)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Applications')\n",
    "\n",
    "# Shade political party in office at time\n",
    "plt.axvspan(months[0], democratic_start, alpha=0.2, color='r')\n",
    "plt.axvspan(democratic_start, democratic_end, alpha=0.2, color='b')\n",
    "plt.axvspan(democratic_end, months[-1], alpha=0.2, color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
